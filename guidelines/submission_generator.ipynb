{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from submission_generator_tools import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-DEFINING USEFUL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## HEADER ##########\n",
    "# Config file description :\n",
    "\n",
    "# network_learning_rate : float : No idea, but certainly linked to the back propagation ? Default : 0.0005.\n",
    "# network_n_classes : int : number of labels in the output. Default : 2.\n",
    "# network_dropout : float : between 0 and 1 : percentage of neurons we want to keep. Default : 0.75.\n",
    "# network_depth : int : number of layers WARNING : factualy, there will be 2*network_depth layers. Default : 6.\n",
    "# network_convolution_per_layer : list of int, length = network_depth : number of convolution per layer. Default : [1 for i in range(network_depth)].\n",
    "# network_size_of_convolutions_per_layer : list of lists of int [number of layers[number_of_convolutions_per_layer]] : Describe the size of each convolution filter.\n",
    "# Default : [[3 for k in range(network_convolution_per_layer[i])] for i in range(network_depth)].\n",
    "# network_features_per_layer : list of lists of int [number of layers[number_of_convolutions_per_layer[2]] : Numer of different filters that are going to be used.\n",
    "# Default : [[64 for k in range(network_convolution_per_layer[i])] for i in range(network_depth)]. WARNING ! network_features_per_layer[k][1] = network_features_per_layer[k+1][0].\n",
    "# network_trainingset : string : describe the trainingset for the network.\n",
    "# network_downsampling : string 'maxpooling' or 'convolution' : the downsampling method.\n",
    "# network_thresholds : list of float in [0,1] : the thresholds for the ground truthes labels.\n",
    "# network_weighted_cost : boolean : whether we use weighted cost for training or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-GENERATING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the name of the files and models, and environment variables.\n",
    "\n",
    "**IMPORTANT TO CHANGE AT EACH GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = 'Guillimin' # Choose between Guillimin and Helios\n",
    "\n",
    "# Warning: model names must finish by \"/\"\n",
    "\n",
    "path_models = '../models/'\n",
    "path_data = '../../../trainingsets/'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the test config files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_list = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config_list.update(generate_dict( network_learning_rate = 0.0005,\n",
    "\t                     network_n_classes = 2,\n",
    "\t                     dropout = 0.75,\n",
    "\t                     structure = [[5,5,5], [3,3,3], [3,3,3], [3,3,3]],  \n",
    "\t                     features_augmentation = 'p10',\n",
    "\t                     network_first_num_features = 15,\n",
    "\t                     trainingset = 'SEM_2classes_reduced',\n",
    "\t                     downsampling = 'convolution',\n",
    "\t                     thresholds = [0, 0.5],\n",
    "\t                     weighted_cost = False,\n",
    "                         batch_size = 8))\n",
    "\n",
    "config_list.update(generate_dict( network_learning_rate = 0.0005,\n",
    "\t                     network_n_classes = 2,\n",
    "\t                     dropout = 0.75,\n",
    "\t                     structure = [[5,5,5], [5,5,5], [3,3,3], [3,3,3]],  \n",
    "\t                     features_augmentation = 'x2',\n",
    "\t                     network_first_num_features = 16,\n",
    "\t                     trainingset = 'SEM_2classes_reduced',\n",
    "\t                     downsampling = 'maxpooling',\n",
    "\t                     thresholds = [0, 0.5],\n",
    "\t                     weighted_cost = False,\n",
    "                         batch_size = 8))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate the bash file that will launch all submissions at once, as well as the required sh files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(path_models + \"/global_submission.sh\",\"w\") # We create the general submission file at the root of the models folder\n",
    "\n",
    "for config_name,config in config_list.iteritems():\n",
    "\n",
    "    submission_filename = \"submission.sh\"\n",
    "    if server == 'Helios':\n",
    "        file.write('msub ')\n",
    "    elif server == 'Guillimin':\n",
    "        file.write('qsub ')\n",
    "    file.write(str(config_name)+'/')\n",
    "    file.write(str(submission_filename))\n",
    "    if server == 'Guillimin':\n",
    "        file.write(' -l nodes=1:gpus=1:exclusive_process') # To avoid a server error. Check that the number of nodes is the good one !\n",
    "    file.write('\\n')\n",
    "    \n",
    "    if server == 'Helios':\n",
    "        generate_heliosjob(submission_filename, 'config_network.json', config,\n",
    "                       path_trainingset = path_data+config['network_trainingset']+'/training/',\n",
    "                       path_model = path_models+config_name\n",
    "                      )\n",
    "    elif server == 'Guillimin':\n",
    "        generate_guilliminjob(submission_filename, 'config_network.json', config,\n",
    "                       path_trainingset = path_data+config['network_trainingset']+'/training/',\n",
    "                       path_model = path_models+config_name\n",
    "                      )\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
