{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from submission_generator_tools import *\n",
    "from AxonDeepSeg.config_tools import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-DEFINING USEFUL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## HEADER ##########\n",
    "# Config file description :\n",
    "\n",
    "# network_learning_rate : float : No idea, but certainly linked to the back propagation ? Default : 0.0005.\n",
    "# network_n_classes : int : number of labels in the output. Default : 2.\n",
    "# network_dropout : float : between 0 and 1 : percentage of neurons we want to keep. Default : 0.75.\n",
    "# network_depth : int : number of layers WARNING : factualy, there will be 2*network_depth layers. Default : 6.\n",
    "# network_convolution_per_layer : list of int, length = network_depth : number of convolution per layer. Default : [1 for i in range(network_depth)].\n",
    "# network_size_of_convolutions_per_layer : list of lists of int [number of layers[number_of_convolutions_per_layer]] : Describe the size of each convolution filter.\n",
    "# Default : [[3 for k in range(network_convolution_per_layer[i])] for i in range(network_depth)].\n",
    "# network_features_per_layer : list of lists of int [number of layers[number_of_convolutions_per_layer[2]] : Numer of different filters that are going to be used.\n",
    "# Default : [[64 for k in range(network_convolution_per_layer[i])] for i in range(network_depth)]. WARNING ! network_features_per_layer[k][1] = network_features_per_layer[k+1][0].\n",
    "# network_trainingset : string : describe the trainingset for the network.\n",
    "# network_downsampling : string 'maxpooling' or 'convolution' : the downsampling method.\n",
    "# network_thresholds : list of float in [0,1] : the thresholds for the ground truthes labels.\n",
    "# network_weighted_cost : boolean : whether we use weighted cost for training or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-GENERATING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the name of the files and models, and environment variables.\n",
    "\n",
    "**IMPORTANT TO CHANGE AT EACH GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = 'Helios' # Choose between Guillimin and Helios\n",
    "\n",
    "# Warning: model names must finish by \"/\"\n",
    "\n",
    "path_models = '../models/'\n",
    "path_data = '../../../trainingsets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PARAMETERS SELECTION **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select what parameters you want to change compared to the default ones. If you want to try several values for a parameter, just use a list for it in dict_params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "L_struct = [{'structure':[[5,5], [3,3], [3,3], [3,3]], 'features_augmentation':'x2', 'network_first_num_features':16}]\n",
    "\n",
    "dict_params = {'network_batch_norm_decay':0.7,\n",
    "              'network_additional_parameters':[{'batch_norm_decay_ending_decay':0.999,\n",
    "                                               'batch_norm_decay_decay_period':2000,\n",
    "                                               'batch_norm_decay_decay_activate':False,\n",
    "                                               'learning_rate_decay_activate':True,\n",
    "                                               'learning_rate_decay_period':120\n",
    "                                              },\n",
    "                                              {'batch_norm_decay_ending_decay':0.999,\n",
    "                                               'batch_norm_decay_decay_period':2000,\n",
    "                                               'batch_norm_decay_decay_activate':False,\n",
    "                                               'learning_rate_decay_activate':True,\n",
    "                                               'learning_rate_decay_period':200\n",
    "                                              },\n",
    "                                              {'batch_norm_decay_ending_decay':0.999,\n",
    "                                               'batch_norm_decay_decay_period':2000,\n",
    "                                               'batch_norm_decay_decay_activate':False,\n",
    "                                               'learning_rate_decay_activate':True,\n",
    "                                               'learning_rate_decay_period':240\n",
    "                                              },\n",
    "                                              {'batch_norm_decay_ending_decay':0.999,\n",
    "                                               'batch_norm_decay_decay_period':2000,\n",
    "                                               'batch_norm_decay_decay_activate':False,\n",
    "                                               'learning_rate_decay_activate':True,\n",
    "                                               'learning_rate_decay_period':80\n",
    "                                              },\n",
    "                                              {'batch_norm_decay_ending_decay':0.999,\n",
    "                                               'batch_norm_decay_decay_period':2000,\n",
    "                                               'batch_norm_decay_decay_activate':False,\n",
    "                                               'learning_rate_decay_activate':True,\n",
    "                                               'learning_rate_decay_period':400\n",
    "                                              }\n",
    "                                              ]\n",
    "              }\n",
    "\n",
    "\n",
    "config_list = grid_config(L_struct, dict_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "walltime_hours = 12 # Change here the duration of each task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SUBMISSION FILES GENERATION **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if server == 'Helios':\n",
    "    path_project = 'maxime'\n",
    "    path_venv = '/home/maxwab/tf11-py27'\n",
    "elif server == 'Guillimin':\n",
    "    path_project = '/gs/project/rrp-355-aa/maxwab'\n",
    "    path_venv = '~/maxwab/tf11-py27'\n",
    "else:\n",
    "    raise ValueError(\"Error, no correct server selected\")\n",
    "    \n",
    "# Maxime values :\n",
    "\n",
    "#if server == 'Helios':\n",
    "#    path_project = 'maxime'\n",
    "#    path_venv = '/home/maxwab/tf11-py27'\n",
    "#elif server == 'Guillimin':\n",
    "#    path_project = '/gs/project/rrp-355-aa/maxwab'\n",
    "#    path_venv = '~/maxwab/tf11-py27'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate the bash file that will launch all submissions at once, as well as the required sh files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = open(path_models + \"/global_submission.sh\",\"w\") # We create the general submission file at the root of the models folder\n",
    "\n",
    "for config_name,config in config_list.iteritems():\n",
    "\n",
    "    submission_filename = \"submission.sh\"\n",
    "    if server == 'Helios':\n",
    "        file.write('msub ')\n",
    "    elif server == 'Guillimin':\n",
    "        file.write('qsub ')\n",
    "    file.write(str(config_name)+'/')\n",
    "    file.write(str(submission_filename))\n",
    "    if server == 'Guillimin':\n",
    "        file.write(' -l nodes=1:gpus=1:exclusive_process') # To avoid a server error. Check that the number of nodes is the good one !\n",
    "    file.write('\\n')\n",
    "    \n",
    "    if server == 'Helios':\n",
    "        generate_heliosjob(path_project, path_venv, submission_filename, 'config_network.json', config,\n",
    "                       path_trainingset = path_data+config['network_trainingset']+'/training/',\n",
    "                       path_model = path_models+config_name, walltime = 3600*walltime_hours-30\n",
    "                      )\n",
    "    elif server == 'Guillimin':\n",
    "        generate_guilliminjob(path_project, path_venv, submission_filename, 'config_network.json', config,\n",
    "                       path_trainingset = path_data+config['network_trainingset']+'/training/',\n",
    "                       path_model = path_models+config_name, walltime = 3600*walltime_hours-30\n",
    "                      )\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
