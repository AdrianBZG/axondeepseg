{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION GENERATOR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from submission_generator_tools import *\n",
    "from AxonDeepSeg.config_tools import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-DEFINING USEFUL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########## HEADER ##########\n",
    "# Config file description :\n",
    "\n",
    "# network_learning_rate : float : No idea, but certainly linked to the back propagation ? Default : 0.0005.\n",
    "# network_n_classes : int : number of labels in the output. Default : 2.\n",
    "# network_dropout : float : between 0 and 1 : percentage of neurons we want to keep. Default : 0.75.\n",
    "# network_depth : int : number of layers WARNING : factualy, there will be 2*network_depth layers. Default : 6.\n",
    "# network_convolution_per_layer : list of int, length = network_depth : number of convolution per layer. Default : [1 for i in range(network_depth)].\n",
    "# network_size_of_convolutions_per_layer : list of lists of int [number of layers[number_of_convolutions_per_layer]] : Describe the size of each convolution filter.\n",
    "# Default : [[3 for k in range(network_convolution_per_layer[i])] for i in range(network_depth)].\n",
    "# network_features_per_layer : list of lists of int [number of layers[number_of_convolutions_per_layer[2]] : Numer of different filters that are going to be used.\n",
    "# Default : [[64 for k in range(network_convolution_per_layer[i])] for i in range(network_depth)]. WARNING ! network_features_per_layer[k][1] = network_features_per_layer[k+1][0].\n",
    "# network_trainingset : string : describe the trainingset for the network.\n",
    "# network_downsampling : string 'maxpooling' or 'convolution' : the downsampling method.\n",
    "# network_thresholds : list of float in [0,1] : the thresholds for the ground truthes labels.\n",
    "# network_weighted_cost : boolean : whether we use weighted cost for training or not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-GENERATING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the name of the files and models, and environment variables.\n",
    "\n",
    "**IMPORTANT TO CHANGE AT EACH GENERATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "server = 'Helios' # Choose between Guillimin and Helios\n",
    "\n",
    "# Warning: model names must finish by \"/\"\n",
    "\n",
    "path_models = '../models/'\n",
    "path_data = '../../../trainingsets/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** PARAMETERS SELECTION **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select what parameters you want to change compared to the default ones. If you want to try several values for a parameter, just use a list for it in dict_params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'network_additional_parameters': {'batch_norm_decay_decay_activate': True,\n",
       "  'batch_norm_decay_decay_period': 4800,\n",
       "  'batch_norm_decay_ending_decay': 0.9,\n",
       "  'learning_rate_decay_activate': True,\n",
       "  'learning_rate_decay_period': 120,\n",
       "  'learning_rate_decay_rate': 0.99},\n",
       " 'network_batch_norm': True,\n",
       " 'network_batch_norm_decay': 0.7,\n",
       " 'network_batch_size': 8,\n",
       " 'network_convolution_per_layer': [2, 2, 2, 2],\n",
       " 'network_data_augmentation': {'transformations': {'0_shifting': True,\n",
       "   '1_rescaling': True,\n",
       "   '2_random_rotation': False,\n",
       "   '3_elastic': True,\n",
       "   '4_flipping': True,\n",
       "   '5_noise_addition': False},\n",
       "  'type': 'all'},\n",
       " 'network_depth': 4,\n",
       " 'network_downsampling': 'convolution',\n",
       " 'network_dropout': 0.75,\n",
       " 'network_features_per_convolution': [[[1, 16], [16, 16]],\n",
       "  [[16, 32], [32, 32]],\n",
       "  [[32, 64], [64, 64]],\n",
       "  [[64, 128], [128, 128]]],\n",
       " 'network_learning_rate': 0.001,\n",
       " 'network_n_classes': 3,\n",
       " 'network_size_of_convolutions_per_layer': [[5, 5, 5],\n",
       "  [3, 3, 3],\n",
       "  [3, 3, 3],\n",
       "  [3, 3, 3]],\n",
       " 'network_thresholds': [0, 0.2, 0.8],\n",
       " 'network_trainingset': 'SEM_3classes_reduced',\n",
       " 'network_weighted_cost': False,\n",
       " 'network_weighted_cost_parameters': {'balanced_activate': True,\n",
       "  'balanced_weights': [1.1, 1, 1.3],\n",
       "  'boundaries_activate': False,\n",
       "  'boundaries_sigma': 2}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_configuration()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "L_struct = [{'structure':[[5,5], [3,3], [3,3], [3,3]], 'features_augmentation':'x2', 'network_first_num_features':16}]\n",
    "\n",
    "dict_params = {'network_weighted_cost':True,\n",
    "               'network_weighted_cost_parameters': [{'balanced_weights': [0.98, 0.89, 1.15]}]\n",
    "              }\n",
    "\n",
    "\n",
    "config_list = grid_config(L_struct, dict_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Options**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "walltime_hours = 12 # Change here the duration of each task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv_3c_d4_c2_k3__0-3363': {'network_additional_parameters': {'batch_norm_decay_decay_activate': True,\n",
       "   'batch_norm_decay_decay_period': 4800,\n",
       "   'batch_norm_decay_ending_decay': 0.9,\n",
       "   'learning_rate_decay_activate': True,\n",
       "   'learning_rate_decay_period': 120,\n",
       "   'learning_rate_decay_rate': 0.99},\n",
       "  'network_batch_norm': True,\n",
       "  'network_batch_norm_decay': 0.7,\n",
       "  'network_batch_size': 8,\n",
       "  'network_convolution_per_layer': [2, 2, 2, 2],\n",
       "  'network_data_augmentation': {'transformations': {'0_shifting': True,\n",
       "    '1_rescaling': True,\n",
       "    '2_random_rotation': False,\n",
       "    '3_elastic': True,\n",
       "    '4_flipping': True,\n",
       "    '5_noise_addition': False},\n",
       "   'type': 'all'},\n",
       "  'network_depth': 4,\n",
       "  'network_downsampling': 'convolution',\n",
       "  'network_dropout': 0.75,\n",
       "  'network_features_per_convolution': [[[1, 16], [16, 16]],\n",
       "   [[16, 32], [32, 32]],\n",
       "   [[32, 64], [64, 64]],\n",
       "   [[64, 128], [128, 128]]],\n",
       "  'network_learning_rate': 0.001,\n",
       "  'network_n_classes': 3,\n",
       "  'network_size_of_convolutions_per_layer': [[5, 5], [3, 3], [3, 3], [3, 3]],\n",
       "  'network_thresholds': [0, 0.2, 0.8],\n",
       "  'network_trainingset': 'SEM_3classes_reduced',\n",
       "  'network_weighted_cost': True,\n",
       "  'network_weighted_cost_parameters': {'balanced_activate': True,\n",
       "   'balanced_weights': [0.98, 0.89, 1.15],\n",
       "   'boundaries_activate': False,\n",
       "   'boundaries_sigma': 2}}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** SUBMISSION FILES GENERATION **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if server == 'Helios':\n",
    "    path_project = 'maxime'\n",
    "    path_venv = '/home/maxwab/tf11-py27'\n",
    "elif server == 'Guillimin':\n",
    "    path_project = '/gs/project/rrp-355-aa/maxwab'\n",
    "    path_venv = '~/maxwab/tf11-py27'\n",
    "else:\n",
    "    raise ValueError(\"Error, no correct server selected\")\n",
    "    \n",
    "# Maxime values :\n",
    "\n",
    "#if server == 'Helios':\n",
    "#    path_project = 'maxime'\n",
    "#    path_venv = '/home/maxwab/tf11-py27'\n",
    "#elif server == 'Guillimin':\n",
    "#    path_project = '/gs/project/rrp-355-aa/maxwab'\n",
    "#    path_venv = '~/maxwab/tf11-py27'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now generate the bash file that will launch all submissions at once, as well as the required sh files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv_3c_d4_c2_k3__0-3363 created ...\n"
     ]
    }
   ],
   "source": [
    "file = open(path_models + \"/global_submission.sh\",\"w\") # We create the general submission file at the root of the models folder\n",
    "\n",
    "for config_name,config in config_list.iteritems():\n",
    "\n",
    "    submission_filename = \"submission.sh\"\n",
    "    if server == 'Helios':\n",
    "        file.write('msub ')\n",
    "    elif server == 'Guillimin':\n",
    "        file.write('qsub ')\n",
    "    file.write(str(config_name)+'/')\n",
    "    file.write(str(submission_filename))\n",
    "    if server == 'Guillimin':\n",
    "        file.write(' -l nodes=1:gpus=1:exclusive_process') # To avoid a server error. Check that the number of nodes is the good one !\n",
    "    file.write('\\n')\n",
    "    \n",
    "    if server == 'Helios':\n",
    "        generate_heliosjob(path_project, path_venv, submission_filename, 'config_network.json', config,\n",
    "                       path_trainingset = path_data+config['network_trainingset']+'/training/',\n",
    "                       path_model = path_models+config_name, walltime = 3600*walltime_hours-30\n",
    "                      )\n",
    "    elif server == 'Guillimin':\n",
    "        generate_guilliminjob(path_project, path_venv, submission_filename, 'config_network.json', config,\n",
    "                       path_trainingset = path_data+config['network_trainingset']+'/training/',\n",
    "                       path_model = path_models+config_name, walltime = 3600*walltime_hours-30\n",
    "                      )\n",
    "\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
