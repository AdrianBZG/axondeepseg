{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET CREATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1-IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from AxonDeepSeg.data import dataset_building\n",
    "import os, shutil\n",
    "from scipy.misc import imread, imsave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-PARAMETERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we set the path parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_data = '../../data/TEM_3classes_raw/TEM_segmented_train/' # where to find the raw data\n",
    "trainingset_path = '../data/TEM_3classes_512_train/' # where to put the generated dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important! We now define the random seed. This will enable us to reproduce the exact same images each time we use the same random seed.\n",
    "\n",
    "This will be used to enable the generation the same validation set and the same testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rng = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: rng used for the different datasets:\n",
    "- SEM: 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then call the function build_dataset. It will automatically create the dataset in the previously specified folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-CREATING TRAIN AND VALIDATION SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change thresh indices if you want to generate a mask with different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_building.build_dataset(path_data, trainingset_path, thresh_indices=[0, 0.2, 0.8], random_seed=rng, trainRatio=1.0, data_type='TEM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4-HAND CHOOSING TEST SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, you should pick >> **in the generated train set** << the images you want to include in the test set.\n",
    "\n",
    "To do that, move them from the training set path to the test set path.\n",
    "\n",
    "With the usual structure of the project, this looks like this:\n",
    "\n",
    "    -- data/\n",
    "    ---- dataset_1/\n",
    "    ------ training/\n",
    "    -------- train/ __ move images and masks to use for the test set from here __\n",
    "    -------- validation/\n",
    "    ------ testing/ __ put them here __\n",
    "    -------- raw/\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5-RENUMBERING THE TRAINING SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have extracted the images from the training set to the test set, we need to renumber them for our algorithm to be able to work.\n",
    "\n",
    "No need to renumber the test set for the moment as it does not intervene in the training phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "\n",
    "subpath_data = trainingset_path + '/training/Train'\n",
    "temp_path = trainingset_path + '/temp/'\n",
    "os.mkdir(temp_path)\n",
    "\n",
    "# Renumbering data\n",
    "\n",
    "for data in os.listdir(subpath_data):\n",
    "    if 'image' in data:\n",
    "        img = imread(os.path.join(subpath_data, data), flatten=False, mode='L')\n",
    "        imsave(temp_path + '/image_%s.png'%i, img, 'png')\n",
    "        i=i+1\n",
    "    elif 'mask' in data:\n",
    "        mask = imread(os.path.join(subpath_data, data), flatten=False, mode='L')\n",
    "        imsave(temp_path + '/mask_%s.png'%j, mask, 'png')\n",
    "        j=j+1\n",
    "        \n",
    "# Replacing old images and masks by new images and mask\n",
    "\n",
    "filelist = [ f for f in os.listdir(subpath_data) if f.endswith(\".png\") ]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(subpath_data,f))\n",
    "    \n",
    "filelist = [ f for f in os.listdir(temp_path) if f.endswith(\".png\") ]\n",
    "for f in filelist:\n",
    "    shutil.move(os.path.join(temp_path,f),subpath_data)\n",
    "    \n",
    "shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_img, L_mask = [], []\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "subpath_data = trainingset_path + '/training/Validation'\n",
    "temp_path = trainingset_path + '/temp/'\n",
    "os.mkdir(temp_path)\n",
    "\n",
    "# Renumbering data\n",
    "for data in os.listdir(subpath_data):\n",
    "    data_name = data[:-4].split('_')\n",
    "    if 'image' in data:\n",
    "        img = imread(os.path.join(subpath_data, data), flatten=False, mode='L')\n",
    "        L_img.append((img, int(data_name[-1])))\n",
    "\n",
    "    elif 'mask' in data:\n",
    "        mask = imread(os.path.join(subpath_data, data), flatten=False, mode='L')\n",
    "        L_mask.append((mask, int(data_name[-1])))\n",
    "        \n",
    "\n",
    "    # We sort the transformations to make by the number preceding the transformation in the dict in the config file        \n",
    "    L_img_sorted = sorted(L_img, key=lambda x: int(x[1])) \n",
    "    L_mask_sorted = sorted(L_mask, key=lambda x: int(x[1]))\n",
    "    \n",
    "for img,k in L_img_sorted:\n",
    "    imsave(temp_path + '/image_%s.png'%i, img, 'png')\n",
    "    i = i+1\n",
    "    \n",
    "for mask,k in L_mask_sorted:\n",
    "    imsave(temp_path + '/mask_%s.png'%j, mask, 'png')\n",
    "    j =j+1\n",
    "\n",
    "# Replacing old images and masks by new images and mask\n",
    "\n",
    "filelist = [ f for f in os.listdir(subpath_data) if f.endswith(\".png\") ]\n",
    "for f in filelist:\n",
    "    os.remove(os.path.join(subpath_data,f))\n",
    "    \n",
    "filelist = [ f for f in os.listdir(temp_path) if f.endswith(\".png\") ]\n",
    "for f in filelist:\n",
    "    shutil.move(os.path.join(temp_path,f),subpath_data)\n",
    "    \n",
    "shutil.rmtree(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You're all done!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
