{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation notebook\n",
    "\n",
    "This notebook shows how to build a dataset for the training of a new model in AxonDeepSeg. It covers the following steps:\n",
    "\n",
    "* How to structure the raw data.\n",
    "* How to define the parameters of the patch extraction and divide the raw labelled dataset into patches.\n",
    "* How to generate the training dataset of patches by combining all raw data patches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 0: IMPORTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AxonDeepSeg.data_management import dataset_building\n",
    "import os, shutil\n",
    "from scipy.misc import imread, imsave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: GENERATE THE DATASET."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Define the parameters of the patch extraction.\n",
    "\n",
    "* **path_raw_data**: Path of the folder that contains the raw data. Each labelled sample of the dataset should be in a different subfolder. For each sample (and subfolder), the expected files are the following:\n",
    "    * *\"image.png\"*: The microscopy sample image (uint8 format).\n",
    "    * *\"mask.png\"*: The microscopy sample image (uint8 format).\n",
    "    * *\"pixel_size_in_micrometer.txt\"*: A one-line text file with the value of the pixel size of the sample. For instance, if the pixel size of the sample is 0.02um, the value in the text file should be \"0.02\".\n",
    "* **path_patched_data**: Path of the folder that will contain the raw data divided into patches. Each sample (i.e. subfolder) of the raw dataset will be divided into patches and saved in this folder. For instance, if a sample of the original data is divided into 10 patches, the corresponding folder in the **path_patched_dataset** will contain 10 image and mask patches, named **image_0.png** to **image_9.png** and **mask_0.png** to **mask_9.png**, respectively. \n",
    "* **patch_size**: The size of the patches in pixels. For instance, a patch size of **128** means that each generated patch will be 128x128 pixels.\n",
    "* **general_pixel_size**: The pixel size (i.e. resolution) of the generated patches in micrometers. The pixel size will be the same for all generated patches. If the selected pixel size is different from the native pixel sizes of the samples, downsampling or upsampling will be performed. Note that the pixel size should be chosen by taking into account the modality of the dataset and the patch size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = '/Users/rudinakaprata/Dropbox/raw_data_SEM/'\n",
    "path_patched_data = '/Users/rudinakaprata/Dropbox/patched_data_SEM/'\n",
    "patch_size = 256\n",
    "general_pixel_size = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__General pixel size :__\n",
    "* SEM\n",
    "  * 256 $\\Rightarrow$ 0.1\n",
    "  * 512 $\\Rightarrow$ 0.1 (because not same semantics as 256 in this case)\n",
    "* TEM\n",
    "  * 256 $\\Rightarrow$ 0.02\n",
    "  * 512 $\\Rightarrow$ 0.01\n",
    "  * 1024 $\\Rightarrow$ 0.005"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important! We now define the random seed. This will enable us to reproduce the exact same images each time we use the same random seed.\n",
    "\n",
    "This will be used to enable the generation the same validation set and the same testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: rng used for the different datasets:\n",
    "- SEM: 2017"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then call the function build_dataset. It will automatically create the dataset in the previously specified folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-CREATING TRAIN AND VALIDATION SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change thresh indices if you want to generate a mask with different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]/Users/rudinakaprata/Documents/Aldo/ads_feb/ads_may/lib/python2.7/site-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n",
      "100%|██████████| 8/8 [00:10<00:00,  1.35s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_building.raw_img_to_patches(path_raw_data, path_patched_data, thresh_indices = [0, 0.2, 0.8], patch_size=patch_size, resampling_resolution=general_pixel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter here the path of the new dataset (will be created if non existent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '/Users/rudinakaprata/Dropbox/processed_final_data_SEM/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_building.patched_to_dataset(path_patched_data, path_dataset, type_='unique', random_seed=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
