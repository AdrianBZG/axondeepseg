{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset creation notebook\n",
    "\n",
    "This notebook shows how to build a dataset for the training of a new model in AxonDeepSeg. It covers the following steps:\n",
    "\n",
    "* How to structure the raw data.\n",
    "* How to define the parameters of the patch extraction and divide the raw labelled dataset into patches.\n",
    "* How to generate the training dataset of patches by combining all raw data patches.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 0: IMPORTS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from AxonDeepSeg.data_management import dataset_building\n",
    "import os, shutil\n",
    "from scipy.misc import imread, imsave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1: GENERATE THE DATASET.\n",
    "\n",
    "### Suggested procedure for training/validation split of the dataset:\n",
    "\n",
    "* From the raw dataset folder, split the raw samples (subfolders) into training and validation. For instance, if you have 6 samples of similar image size, you can keep 5 of them for the training and the remaining one for the validation. \n",
    "\n",
    "#### The original folder structure before the training/validation split:\n",
    "\n",
    "* ***folder_raw_data***\n",
    "    * **Train**\n",
    "        * **sample1**\n",
    "            * *image.png*\n",
    "            * *mask.png*\n",
    "            * *pixel_size_in_micrometer.txt*\n",
    "        * **sample2**\n",
    "            * *image.png*\n",
    "            * *mask.png*\n",
    "            * *pixel_size_in_micrometer.txt*\n",
    "            \n",
    "            ...\n",
    "            \n",
    "        * **sample5**\n",
    "            * *image.png*\n",
    "            * *mask.png*\n",
    "            * *pixel_size_in_micrometer.txt*\n",
    "\n",
    "* Put the 8 selected samples in the Train subfolder and the other 2 in the Validation subfolder.\n",
    "* Run the raw_img_to_patches function on both the Train and Validation subfolders to split the data into patches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1. Define the parameters of the patch extraction.\n",
    "\n",
    "* **path_raw_data**: Path of the folder that contains the raw data. Each labelled sample of the dataset should be in a different subfolder. For each sample (and subfolder), the expected files are the following:\n",
    "    * *\"image.png\"*: The microscopy sample image (uint8 format).\n",
    "    * *\"mask.png\"*: The microscopy sample image (uint8 format).\n",
    "    * *\"pixel_size_in_micrometer.txt\"*: A one-line text file with the value of the pixel size of the sample. For instance, if the pixel size of the sample is 0.02um, the value in the text file should be **\"0.02\"**.\n",
    "    \n",
    "* **path_patched_data**: Path of the folder that will contain the raw data divided into patches. Each sample (i.e. subfolder) of the raw dataset will be divided into patches and saved in this folder. For instance, if a sample of the original data is divided into 10 patches, the corresponding folder in the **path_patched_dataset** will contain 10 image and mask patches, named **image_0.png** to **image_9.png** and **mask_0.png** to **mask_9.png**, respectively. \n",
    "\n",
    "* **patch_size**: The size of the patches in pixels. For instance, a patch size of **128** means that each generated patch will be 128x128 pixels.\n",
    "\n",
    "* **general_pixel_size**: The pixel size (i.e. resolution) of the generated patches in micrometers. The pixel size will be the same for all generated patches. If the selected pixel size is different from the native pixel sizes of the samples, downsampling or upsampling will be performed. Note that the pixel size should be chosen by taking into account the modality of the dataset and the patch size.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "path_raw_data_train = '/Users/rudinakaprata/Dropbox/raw_data_SEM/Train'\n",
    "path_patched_data_train = '/Users/rudinakaprata/Dropbox/patched_data_SEM/Train'\n",
    "\n",
    "path_raw_data_validation = '/Users/rudinakaprata/Dropbox/raw_data_SEM/Validation'\n",
    "path_patched_data_validation = '/Users/rudinakaprata/Dropbox/patched_data_SEM/Validation'\n",
    "\n",
    "\n",
    "\n",
    "patch_size = 256\n",
    "general_pixel_size = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important! We now define the random seed. This will enable us to reproduce the exact same images each time we use the same random seed.\n",
    "\n",
    "This will be used to enable the generation the same validation set and the same testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suggested procedure for training/validation split of the dataset:\n",
    "\n",
    "* From the raw dataset folder, split the raw samples into training and validation. For instance, if you have 10 samples of similar size, you can keep 8 of them for the training and the other 2 for the validation.\n",
    "* Put the 8 selected samples in the Train subfolder and the other 2 in the Validation subfolder.\n",
    "* Run the raw_img_to_patches function on both the Train and Validation subfolders to split the data into patches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then call the function build_dataset. It will automatically create the dataset in the previously specified folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3-CREATING TRAIN AND VALIDATION SET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change thresh indices if you want to generate a mask with different classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:06<00:00,  1.02it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_building.raw_img_to_patches(path_raw_data_train, path_patched_data_train, thresh_indices = [0, 0.2, 0.8], patch_size=patch_size, resampling_resolution=general_pixel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter here the path of the new dataset (will be created if non existent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_dataset = '/Users/rudinakaprata/Dropbox/processed_final_data_SEM/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:08<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "dataset_building.patched_to_dataset(path_patched_data, path_dataset, type_='unique', random_seed=2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
